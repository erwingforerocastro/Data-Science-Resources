{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IntroductionFunctionalAPI.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHBELANoGh1RxkYsiYnZ+s"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7EVRHMrskOv2","colab_type":"text"},"source":["#Deep Learning con Python\n","`Autor: Erwing FC \n","~erwingforerocastro@gmail.com`"]},{"cell_type":"markdown","metadata":{"id":"paQzAtJZtmgG","colab_type":"text"},"source":["###Multi-input model"]},{"cell_type":"markdown","metadata":{"id":"utRQKswjlsUg","colab_type":"text"},"source":["Un modelo típico de preguntas y respuestas tiene dos entradas: una pregunta en lenguaje natural y un fragmento de texto (como un artículo de noticias) que proporciona información que se utilizará para responder la pregunta."]},{"cell_type":"code","metadata":{"id":"EcH8OTookLaa","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras import layers\n","from keras import Input\n","\n","text_vocabulary_size = 10000\n","question_vocabulary_size = 10000\n","answer_vocabulary_size = 500\n","\n","#el tamaño de la entrada de la red\n","#el embedding del texto de entrada\n","#la capa de LSTM del texto de entrada\n","text_input = Input(shape=(None,), dtype='int32', name='text')\n","embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n","encoded_text = layers.LSTM(32)(embedded_text)\n","\n","#el tamaño de la entrada de la red\n","#el embedding de la pregunta \n","#la capa de LSTM de la pregunta \n","question_input = Input(shape=(None,),dtype='int32',name='question')\n","embedded_question=layers.Embedding(32,question_vocabulary_size)(question_input)\n","encoded_question=layers.LSTM(16)(embedded_question)\n","\n","#unimos ambas codificaciones\n","concatenated=layers.concatenate([encoded_text,encoded_question],axis=-1)\n","#agregamos la ultima capa softmax de la respuesta\n","answer=layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n","\n","#agregamos la(s) entrada(s) y la ultima capa de la red\n","net=Model([text_input,question_input],answer)\n","#compilacion\n","net.compile(optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HNceOwupo_De","colab_type":"text"},"source":["Alimentando un modelo de entradas multiples"]},{"cell_type":"code","metadata":{"id":"g9UO2gqlo-no","colab_type":"code","colab":{}},"source":["import numpy as np\n","num_samples=1000\n","max_length=100\n","\n","text=np.random.randint(1,text_vocabulary_size,size=(num_samples,max_length))\n","question=np.random.randint(1,question_vocabulary_size,size=(num_samples,max_length))\n","answers=np.random.randint(0,1,size=(num_samples,answer_vocabulary_size)) #one-hot encoding \n","\n","#entrenamiento\n","\n","net.fit([text,question],answers,epochs=10,batch_size=128) #entrenando con una lista de entradas\n","net.fit({'text': text, 'question': question}, answers,    #entrenando usando un diccionario de entradas\n","            epochs=10, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqJcDVbwttKR","colab_type":"text"},"source":["###Multi-output Model"]},{"cell_type":"markdown","metadata":{"id":"4bYWdYJQuN3V","colab_type":"text"},"source":["predecir simultáneamente diferentes propiedades de los datos, como una red que toma como entrada una serie de publicaciones en redes sociales de una sola persona anónima y trata de predecir los atributos de esa persona, como la edad, el género , y nivel de ingresos"]},{"cell_type":"code","metadata":{"id":"x5Cti0RwtvKx","colab_type":"code","colab":{}},"source":["from keras import layers\n","from keras import Input\n","from keras.models import Model\n","\n","vocabulary_size = 50000\n","num_income_groups = 10\n","\n","#estructura de la red\n","posts_input = Input(shape=(None,), dtype='int32', name='posts')\n","embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n","x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","\n","#output o ultima capa de la red\n","age_prediction = layers.Dense(1, name='age')(x) #edad\n","income_prediction = layers.Dense(num_income_groups,\n","                                 activation='softmax',\n","                                 name='income')(x) #nivel de ingresos\n","gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x) #genero\n","\n","#agregamos las salidas al modelo\n","net = Model(posts_input,[age_prediction, income_prediction, gender_prediction])\n","\n","#compilamos\n","net.compile(optimizer='rmsprop',\n","            loss=['mse','categorical_crossentropy','binary_crossentropy'],\n","            loss_weights=[0.25, 1., 10.]) #pesos para equilibrar los tamaños de las perdidas\n","\n","#equivalente si las salidas de la red contienen la propiedad name\n","# model.compile(optimizer='rmsprop',\n","#               loss={'age': 'mse',\n","#                     'income': 'categorical_crossentropy',\n","#                     'gender': 'binary_crossentropy'},\n","#                 loss_weights={'age': 0.25,\n","#                               'income': 1.,\n","#                               'gender': 10.})\n","\n","#entrenamos\n","model.fit(posts, [age_targets, income_targets, gender_targets],\n","                  epochs=10, batch_size=64)\n","\n","#equivalente si las salidas de la red contienen la propiedad name\n","# model.fit(posts, {'age': age_targets,\n","#                   'income': income_targets,\n","#                   'gender': gender_targets},\n","#           epochs=10, batch_size=64)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pmet-XpGtgYY","colab_type":"text"},"source":["###Siames LSTM"]},{"cell_type":"markdown","metadata":{"id":"omkHV-Qrtieo","colab_type":"text"},"source":["Dos entradas una capa"]},{"cell_type":"code","metadata":{"id":"3jFS689I3Tj6","colab_type":"code","colab":{}},"source":["from keras import layers\n","from keras import Input\n","from keras.models import Model\n","#LSTM\n","lstm = layers.LSTM(32)\n","#las entradas y conexiones con LSTM\n","left_input = Input(shape=(None, 128))\n","left_output = lstm(left_input)\n","right_input = Input(shape=(None, 128))\n","right_output = lstm(right_input)\n","#la union\n","merged = layers.concatenate([left_output, right_output], axis=-1)\n","#la capa de salida\n","predictions = layers.Dense(1, activation='sigmoid')(merged)\n","#le damos al modelo las capas de entrada y de salida\n","model = Model([left_input, right_input], predictions)\n","#entrenamos (H)\n","model.fit([left_data, right_data], targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oX_lUIz2tybf","colab_type":"text"},"source":["###Xception"]},{"cell_type":"code","metadata":{"id":"JJ6HBb9ztz0n","colab_type":"code","colab":{}},"source":["from keras import layers\n","from keras import applications\n","from keras import Input\n","#la capa\n","xception_base = applications.Xception(weights=None,\n","include_top=False)\n","#las entradas\n","left_input = Input(shape=(250, 250, 3))\n","right_input = Input(shape=(250, 250, 3))\n","#la conexion con la capa\n","left_features = xception_base(left_input)\n","right_input = xception_base(right_input)\n","#la union\n","merged_features = layers.concatenate(\n","[left_features, right_input], axis=-1)"],"execution_count":null,"outputs":[]}]}