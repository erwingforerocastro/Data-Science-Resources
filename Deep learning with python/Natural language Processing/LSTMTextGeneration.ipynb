{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTMTextGeneration.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP14wygJNRf1gwL6y4deZcT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ln3IafqdMu8b","colab_type":"text"},"source":["#Deep Learning con Python\n","`Autor: Erwing FC \n","~erwingforerocastro@gmail.com`"]},{"cell_type":"code","metadata":{"id":"-tJ92JfeMKlk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596729436678,"user_tz":300,"elapsed":2535,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"3d2d71ad-c787-4aa0-93b3-f8abd7a487eb"},"source":["import keras\n","import numpy as np\n","path = keras.utils.get_file('nietzsche.txt',\n","                            origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","\n","text = open(path).read().lower()\n","print('Tamaño del cuerpo:', len(text))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n","606208/600901 [==============================] - 0s 1us/step\n","Tamaño del cuerpo: 600893\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pOwbSF_EUvqk","colab_type":"text"},"source":["###Preparacion de los datos"]},{"cell_type":"code","metadata":{"id":"sw_tnDYwPjYg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596729442970,"user_tz":300,"elapsed":8818,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"130f428f-c56b-4ee2-9a29-3a97f5ca21b4"},"source":["maxlen = 60 #secuencias de 60 caracteres\n","step = 3    #nueva secuencia cada 3 caracteres\n","sentences = [] #secuencias\n","next_chars = [] #palabra siguiente de esa secuencia\n","\n","for i in range(0, len(text) - maxlen, step): #(0,600833,3)\n","  sentences.append(text[i: i + maxlen])      # por ejemplo: text[0:60] tomara caracteres de 0 hasta 59\n","  next_chars.append(text[i + maxlen])        # por ejemplo: text[60] tomara el caracter 60\n","print('Numero de secuencias:', len(sentences))\n","\n","chars = sorted(list(set(text))) #lista de unicos caracteres en el cuerpo\n","print('Caracteres unicos:', len(chars))\n","\n","char_indices = dict((char, chars.index(char)) for char in chars) #lista de caracteres con su indice \n","\n","print('Vectorización...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) \n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","\n","#se realiza one-hot encoding\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","        y[i, char_indices[next_chars[i]]] = 1"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Numero de secuencias: 200278\n","Caracteres unicos: 57\n","Vectorización...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"umQmfjheS2EL","colab_type":"text"},"source":["###Estructura y compilación"]},{"cell_type":"code","metadata":{"id":"wO7xd7uASi23","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596729448107,"user_tz":300,"elapsed":13945,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}}},"source":["from keras import layers\n","\n","net = keras.models.Sequential()\n","net.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n","net.add(layers.Dense(len(chars), activation='softmax'))\n","\n","#compilacion\n","optimizer = keras.optimizers.RMSprop(lr=0.01)\n","net.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8IZq7NkFU1t2","colab_type":"text"},"source":["###Predicciones"]},{"cell_type":"markdown","metadata":{"id":"8Qj3ZLJajRiL","colab_type":"text"},"source":["Funcion de temperatura:\n","<br><br>\n","<img src=\"https://i.stack.imgur.com/HYyQT.jpg\">\n"]},{"cell_type":"code","metadata":{"id":"a6YzE7SdWOZw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596729448109,"user_tz":300,"elapsed":13942,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}}},"source":["#Función para muestrear el siguiente caracter dadas las predicciones del modelo\n","\n","def sample(preds, temperature=1.0):\n","  preds = np.asarray(preds).astype('float64')\n","  preds = np.log(preds) / temperature #logNat(x)/1\n","  exp_preds = np.exp(preds)           #e^x\n","  preds = exp_preds / np.sum(exp_preds) \n","  probas = np.random.multinomial(1, preds, 1) #probabilidad\n","  return np.argmax(probas) #la maxima probabilidad"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFuJK1kgZual","colab_type":"code","colab":{}},"source":["import random\n","import sys\n","\n","for epoch in range(1, 60): #se entrena el modelo por 60 epocas\n","    print('epoca', epoch)\n","    net.fit(x, y, batch_size=128, epochs=1) #se entrena el modelo con solo 1 epoca\n","    #seleccionamos una seccion de texto aletoria\n","    start_index = random.randint(0, len(text) - maxlen - 1)\n","    generated_text = text[start_index: start_index + maxlen]\n","    print('--- Generando con semilla: \"' + generated_text + '\"')\n","    \n","    for temperature in [0.2, 0.5, 1.0, 1.2]: #se intenta una gama de diferentes temperaturas de muestreo\n","        print('------ temperatura:', temperature)\n","        sys.stdout.write(generated_text)\n","        for i in range(400): #Genera 400 caracteres, comenzando por el texto semilla\n","\n","            sampled = np.zeros((1, maxlen, len(chars)))  #one-hot encoding del texto\n","            for t, char in enumerate(generated_text):\n","                sampled[0, t, char_indices[char]] = 1.\n","                \n","            #realizamos una prediccion\n","            preds = net.predict(sampled, verbose=0)[0]\n","\n","            #probabilidad del siguiente caracter\n","            next_index = sample(preds, temperature)\n","            next_char = chars[next_index]\n","\n","            #agregamos el caracter predicho\n","            generated_text += next_char\n","            generated_text = generated_text[1:] #cambiamos el texto quitamos la primera palabra y dejamos la siguiente\n","            sys.stdout.write(next_char)"],"execution_count":null,"outputs":[]}]}