{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simpleTextClassificationWithEmbeddingIMDB.ipynb","provenance":[{"file_id":"14XLy7gRXSF5nP4gbjWKiFjDACFcoWNWG","timestamp":1595511500903},{"file_id":"1N88GECKRf8pLNUd868q0WHy5FaYQ914d","timestamp":1594129919188}],"collapsed_sections":[],"authorship_tag":"ABX9TyO6rS2+28/IcSvWN9zfiPHm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I7pgV4r1OGDY","colab_type":"text"},"source":["#Deep Learning con Python\n","`Autor: Erwing FC \n","~erwingforerocastro@gmail.com`"]},{"cell_type":"markdown","metadata":{"id":"82dUF4BRPfrq","colab_type":"text"},"source":["El siguiente ejercicio es un clasificador de texto segun el sentimiento del mismo (positivo o negativo) en base a comentarios de IMDB."]},{"cell_type":"code","metadata":{"id":"FhL37pwvjcTq","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1595600110060,"user_tz":300,"elapsed":783548,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"0e9b3d2f-32b8-4287-dfc0-b275be6d270c"},"source":["import os\n","from google.colab import files\n","import zipfile\n","#subimos el archivo guardado en external files / Natural Language processing\n","files.upload()\n","!unzip aclImdb.zip"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-2eec58f7-f02d-4f1b-b882-f3488a03e60b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2eec58f7-f02d-4f1b-b882-f3488a03e60b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving aclImdb.zip to aclImdb.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WnLYC5hAmQ-Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1595600110913,"user_tz":300,"elapsed":757369,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"d7df10d0-f926-4a58-f7a7-5cdd51b5641f"},"source":["imdb_dir='aclImdb'\n","train_dir=os.path.join(imdb_dir,'train') #archivo de entrenamiento\n","\n","labels=[]\n","texts=[]\n","\n","\n","for label_type in ['neg','pos']:\n","  dir_name=os.path.join(train_dir,label_type) \n","  for fname in os.listdir(dir_name):\n","    if fname[-4:]=='.txt': #si es un archivo de texto\n","      f=open(os.path.join(dir_name,fname)) #lo abrimos\n","      texts.append(f.read()) #lo guardamos en texts\n","      f.close()              #cerramos\n","      if label_type=='neg':  #guardamos la etiqueta correspondiente en labels\n","        labels.append(0)\n","      else:\n","        labels.append(1)\n","        \n","#el primer ejemplo:     \n","print(texts[0])\n","print(labels[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mr Perlman gives a standout performance (as usual). Sadly, he has to struggle with an underwritten script and some nonsensical set pieces.<br /><br />Larsen is in \"Die Hard\" mode complete with singlet and bulging muscles, I'm sure he could do better but seems satisfied to grimace and snarl through his part.<br /><br />The lovely Erika is very decorative (even though fully clothed!) and shows some signs of \"getting\" acting at last.<br /><br />SFX are mainly poor CGI and steals from other movies.<br /><br />The shootouts are pitiful - worthy of the A-Team<br /><br />Not even worth seeing for Perlman - AVOID\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EWmeiC2MMuW9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595600121617,"user_tz":300,"elapsed":10697,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"32dca6f7-63ba-4e8f-83f8-937b6ba88797"},"source":["#recordemos que los embedding preentrenados son buenos en pocos datos de capacitación, en problemas mas especificos pueden no funcionar correctamente\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","maxlen = 100  #las reseñas seran solo de 100 \n","training_samples = 200  #ejemplos de entrenamiento 200\n","validation_samples = 10000 #ejemplos de validacion 10000\n","max_words = 10000 #las primeras 10000 palabras del diccionario\n","\n","tokenizer=Tokenizer(num_words=max_words) # le asignamos al tokenizador un valor maximo de palabras de 10000\n","tokenizer.fit_on_texts(texts)            # le pasamos los textos para que extraiga los tokens  \n","sequences=tokenizer.texts_to_sequences(texts) #convertimos el texto en secuencias en base a los tokens anteriores ej: \n","\n","#texts='hola lola' tokenizer.word_index = {'a':0,'l':1,'h':2,'o':3} tokenizer.texts_to_sequences(texts)= [[2],[3],[1],[0],[],[1],[3],[1],[0]]\n","\n","word_index=tokenizer.word_index\n","print('Encontrados %s unicos tokens.'%len(word_index))\n","\n","data=pad_sequences(sequences,maxlen=maxlen) #rellenamos de 0'ros los datos que contengan menor dimensionalidad, y sin superar agrupaciones de 100 ej:\n","#agrupaciones de 3: [[1],[2],[3],[],[1]] pad_sequence= [[1,2,3],[0,0,1]]\n","\n","labels=np.asarray(labels) #convertimos las etiquetas de array a numpy array\n","print('Tamaño del tensor de datos:', data.shape)\n","print('Tañamo de las etiquetas:', labels.shape)\n","\n","#mezclamos los datos\n","indices=np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data=data[indices]\n","labels=labels[indices]\n","\n","x_train = data[:training_samples] #200\n","y_train = labels[:training_samples]\n","x_val = data[training_samples: training_samples + validation_samples] #de 200 hasta 10200\n","y_val = labels[training_samples: training_samples + validation_samples]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Encontrados 88582 unicos tokens.\n","Tamaño del tensor de datos: (25000, 100)\n","Tañamo de las etiquetas: (25000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JYk7xrG6XKfO","colab_type":"text"},"source":["Vaya a https://nlp.stanford.edu/projects/glove y descargue los embeddings precalculadas de Wikipedia en inglés de 2014. Es un archivo zip de 822 MB llamado glove.6B.zip, que contiene vectores de incrustación 100 dimensionales para 400,000 palabras (o sin palabras fichas) y descomprimirlo."]},{"cell_type":"code","metadata":{"id":"UAtmpcIubwfA","colab_type":"code","colab":{}},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqk6PBwrXE_U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595600707963,"user_tz":300,"elapsed":11835,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"0bd9632a-479d-40a9-f1cd-f22ae14291b5"},"source":["embeddings_index={} \n","f=open('glove.6B.100d.txt') \n","\n","for line in f:\n","  values=line.split() #limpiamos la linea de espacios\n","  word=values[0]      #traemos la palabra\n","  coefs=np.asarray(values[1:],dtype='float32') #el resto es el embedding de dicha palabra\n","  embeddings_index[word]=coefs                 #guardamos la palabra y le asignamos su embedding\n","f.close() #cerramos\n","print('Encontramos %s vectores de letras.'%len(embeddings_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Encontramos 400000 vectores de letras.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NWL7cnQGInL_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1595600760314,"user_tz":300,"elapsed":1077,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"c9741c46-a17f-4f98-9d9f-4dcb39ef5daf"},"source":["#Preparación de la matriz de incrustaciones de palabras GloVe\n","embedding_dim=100\n","embedding_matrix=np.zeros((max_words,embedding_dim)) #creamos una matriz de 10000x100\n","for word,i in word_index.items(): #recorremos nuestros tokens (recordar que es un diccionario letra:numero)\n","  if i < max_words:               #solo hasta 100\n","    embedding_vector = embeddings_index.get(word) #traemos el vector perteneciente a la letra de nuestro embedding descargado\n","    if embedding_vector is not None:              #si el vector de dicha palabra existe:\n","        embedding_matrix[i] = embedding_vector    #lo guardamos en la matriz\n","#un ejemplo\n","print(embedding_matrix[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-0.038194   -0.24487001  0.72812003 -0.39961001  0.083172    0.043953\n"," -0.39140999  0.3344     -0.57545     0.087459    0.28786999 -0.06731\n","  0.30906001 -0.26383999 -0.13231    -0.20757     0.33395001 -0.33848\n"," -0.31742999 -0.48335999  0.1464     -0.37303999  0.34577     0.052041\n","  0.44946    -0.46970999  0.02628    -0.54154998 -0.15518001 -0.14106999\n"," -0.039722    0.28277001  0.14393     0.23464    -0.31020999  0.086173\n","  0.20397     0.52623999  0.17163999 -0.082378   -0.71787    -0.41531\n","  0.20334999 -0.12763     0.41367     0.55186999  0.57907999 -0.33476999\n"," -0.36559001 -0.54856998 -0.062892    0.26583999  0.30204999  0.99774998\n"," -0.80480999 -3.0243001   0.01254    -0.36941999  2.21670008  0.72201002\n"," -0.24978     0.92136002  0.034514    0.46744999  1.10790002 -0.19358\n"," -0.074575    0.23353    -0.052062   -0.22044     0.057162   -0.15806\n"," -0.30798    -0.41624999  0.37972     0.15006    -0.53211999 -0.20550001\n"," -1.25259995  0.071624    0.70564997  0.49744001 -0.42063001  0.26148\n"," -1.53799999 -0.30223    -0.073438   -0.28312001  0.37103999 -0.25217\n","  0.016215   -0.017099   -0.38984001  0.87423998 -0.72569001 -0.51058\n"," -0.52028    -0.1459      0.82779998  0.27061999]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MPxI7EnyMEET","colab_type":"text"},"source":["###Estructura del modelo"]},{"cell_type":"code","metadata":{"id":"fyUSRRjhMO2x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1595600785140,"user_tz":300,"elapsed":8022,"user":{"displayName":"erwing Forero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSqzwkFIVUXZwO_YiA5j0s0F86BT964zP7G48RQw=s64","userId":"11018335521342600653"}},"outputId":"73e7bd7f-3ac3-4b67-e0aa-857de75be4c1"},"source":["from keras.models import Sequential\n","from keras.layers import Embedding,Flatten,Dense\n","\n","net=Sequential()\n","net.add(Embedding(max_words,embedding_dim,input_length=maxlen))\n","net.add(Flatten())\n","net.add(Dense(32,activation='relu'))\n","net.add(Dense(1,activation='sigmoid'))\n","net.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 10000)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                320032    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lm70UBS9ORGO","colab_type":"code","colab":{}},"source":["#Carga de embeddings de palabras previamente formadas en la capa de incrustación\n","net.layers[0].set_weights([embedding_matrix])\n","net.layers[0].trainable = False\n","#evitamos que se entrene el embedding, por que ya descargamos uno anteriormente (recordar transfer learning)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehjIOC8PazOS","colab_type":"text"},"source":["###Entrenamiento y evaluación"]},{"cell_type":"code","metadata":{"id":"AIuQWBj0Ol5p","colab_type":"code","colab":{}},"source":["#agregamos la funcion de perdida y de optimizacion\n","net.compile(optimizer='rmsprop',\n","            loss='binary_crossentropy',\n","            metrics=['acc'])\n","#entrenamos el modelo\n","history=net.fit(x_train,y_train,\n","                epochs=10,\n","                batch_size=32,\n","                validation_data=(x_val,y_val))\n","#guardamos los pesos\n","model.save_weights('pre_trained_glove_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnrAmxXCc1-y","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","\n","plt.figure(figsize=(40,20))\n","plt.plot(epochs,acc,'bo',label='Pres. Entrenamiento')\n","plt.plot(epochs,val_acc,'b',label='Pres. Validación')\n","plt.title('Entrenamiento y validacion presición')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8Bs0mL_fxz4","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(40,20))\n","plt.plot(epochs, loss, 'bo', label='Perdida entrenamiento')\n","plt.plot(epochs, val_loss, 'b', label='Perdida validación')\n","plt.title('Entrenamiento y validacion Perdida')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xMNM6_jhvAY","colab_type":"text"},"source":["###Tokenizar los datos del conjunto de prueba"]},{"cell_type":"code","metadata":{"id":"cVcRHptyhuQy","colab_type":"code","colab":{}},"source":["test_dir = os.path.join(imdb_dir, 'test')\n","\n","labels = []\n","texts = []\n","\n","for label_type in ['neg','pos']: \n","  dir_name=os.path.join(test_dir,label_type) \n","  for fname in sorted(os.listdir(dir_name)): #organizamos los archivos \n","       if fname[-4:]=='.txt':\n","         f=open(os.path.join(dir_name,fname))\n","         texts.append(f.read())\n","         f.close()\n","         if label_type=='neg':\n","           labels.append(0)\n","         else:\n","           labels.append(1)\n","\n","sequences=tokenizer.texts_to_sequences(texts)\n","x_test = pad_sequences(sequences, maxlen=maxlen)\n","y_test = np.asarray(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HX0C6beElVEH","colab_type":"code","colab":{}},"source":["#evaluar el modelo con el set de pruebas\n","net.load_weights('pre_trained_glove_model.h5')\n","net.evaluate(x_test,y_test)"],"execution_count":null,"outputs":[]}]}