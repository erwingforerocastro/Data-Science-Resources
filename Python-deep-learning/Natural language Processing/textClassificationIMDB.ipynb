{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"textClassificationIMDB.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNlgBHGah3ibgFsz6+o2K+U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I7pgV4r1OGDY","colab_type":"text"},"source":["#Deep Learning con Python\n","`Autor: Erwing FC \n","~erwingforerocastro@gmail.com`"]},{"cell_type":"markdown","metadata":{"id":"82dUF4BRPfrq","colab_type":"text"},"source":["El siguiente ejercicio es un clasificador de texto segun el sentimiento del mismo (positivo o negativo) en base a comentarios de IMDB."]},{"cell_type":"code","metadata":{"id":"_cJzVnLTOG1H","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IB1VTflBOVzf","colab_type":"code","colab":{}},"source":["#descargamos los datos\n","!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxhSxpxNOqYz","colab_type":"code","colab":{}},"source":["#contenido de los archivos\n","!ls aclImdb \n","!ls aclImdb/test\n","!ls aclImdb/train\n","#contenido de un archivo de entrenamiento postivo\n","!cat aclImdb/train/pos/6248_7.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymFll4ykRHNY","colab_type":"code","colab":{}},"source":["#eliminamos los archivos no necesarios\n","!rm -r aclImdb/train/unsup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZ1iYEBEbba_","colab_type":"code","colab":{}},"source":["# !pip install tf-nightly\n","#comando opcional para instalar las librerias de tf-nightly"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EomZ69lfSYAP","colab_type":"code","colab":{}},"source":["#creamos los dataset necesarios\n","batch_size=32 #tamaño de cada lote\n","raw_train_ds=tf.keras.preprocessing.text_dataset_from_directory(\n","    \"aclImdb/train\",        #ruta\n","    batch_size=batch_size,  #tamaño del lote\n","    validation_split=0.2,   #20% del conjunto sera para validacion\n","    subset=\"training\",      \n","    seed=1337\n",")\n","raw_val_ds=tf.keras.preprocessing.text_dataset_from_directory(\n","    \"aclImdb/train\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=1337\n",")\n","raw_test_ds=tf.keras.preprocessing.text_dataset_from_directory(\n","    \"aclImdb/test\",\n","    batch_size=batch_size,\n",")\n","print(\"Numero de lotes en raw_train_ds: %d\" % tf.data.experimental.cardinality(raw_train_ds))\n","print(\"Numero de lotes en raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds))\n","print(\"Numero de lotes en raw_test_ds: %d\" % tf.data.experimental.cardinality(raw_test_ds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhGa0rSuf-WS","colab_type":"code","colab":{}},"source":["#obervar el contenido de un ejemplo de entrenamiento\n","for text_batch, label_batch in raw_train_ds.take(1):\n","    for i in range(5):\n","        print(text_batch.numpy()[i])\n","        print(label_batch.numpy()[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZsCf-UfgZvw","colab_type":"code","colab":{}},"source":["#preparamos los datos\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import string\n","import re\n","#funcion para eliminar la etiqueta de salto html y la puntuación\n","def funcion_estandarizacion(input_data):\n","  minusculas=tf.strings.lower(input_data)\n","  eliminar_html=tf.strings.regex_replace(minusculas,\"<br />\",\" \")\n","  return tf.strings.regex_replace(\n","      eliminar_html,\"[%s]\" % re.escape(string.punctuation),\"\"\n","  )\n","#constantes del modelo\n","MAX_FEATURES=20000\n","EMBEDDING_DIM=128\n","SEQUENCE_LENGTH=500\n","\n","vectorize_layer=TextVectorization(\n","    standardize=funcion_estandarizacion,\n","    max_tokens=MAX_FEATURES,\n","    output_mode=\"int\",\n","    output_sequence_length=SEQUENCE_LENGTH,\n",")\n","#dataset de solo texto\n","text_ds = raw_train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(text_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiLv70gG4Sqt","colab_type":"code","colab":{}},"source":["#vectorizacion de los datos\n","#opcion 1 hacerlo parte del modelo\n","\n","# text_input=tf.keras.Input(shape=(1,),dtype=tf.string,name=\"text\")\n","# x=vectorize_layer(text_input)\n","# x=layers.Embedding(MAX_FEATURES + 1, EMBEDDING_DIM)(x)\n","\n","#opcion 2 aplcarlo al conjunto de datos de texto\n","def vectorizacion_texto(text,label):\n","  text=tf.expand_dims(text,-1)\n","  return vectorize(text),label\n","\n","#vectorizamos los datos\n","train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n","\n","# Mejoramos el desempeño al obtener los datos de forma asincrona\n","train_ds = train_ds.cache().prefetch(buffer_size=10)\n","val_ds = val_ds.cache().prefetch(buffer_size=10)\n","test_ds = test_ds.cache().prefetch(buffer_size=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rUGR1l7UpM0K","colab_type":"code","colab":{}},"source":["#construimos el modelo \n","from tensorflow.keras import layers\n","#un valor entero como entrada (los indices del vocabulario)\n","inputs =tf.keras.Input(shape=(None,),dtype=\"int64\")\n","\n","#luego mapeamos los indices en un espacio dimensional\n","x=layers.Embedding(MAX_FEATURES,EMBEDDING_DIM)(inputs)\n","x=layers.Dropout(0.5)(x)\n","\n","x=layers.Conv1D(128,7,padding=\"valid\",activation=\"relu\",strides=3)(x)\n","x=layers.Conv1D(128,7,padding=\"valid\",activation=\"relu\",strides=3)(x)\n","x=layers.GlobalMaxPooling1D()(x)\n","\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","\n","predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n","\n","model = tf.keras.Model(inputs, predictions)\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFCj5P1kMTnr","colab_type":"code","colab":{}},"source":["epochs = 3\n","model.fit(train_ds, validation_data=val_ds, epochs=epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MW37H0o7MXeu","colab_type":"code","colab":{}},"source":["#evaluación del modelo\n","model.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wab0fTPGMhNu","colab_type":"code","colab":{}},"source":["# Una entrada de texto\n","inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n","# convercion de texto a indices del vocabulario\n","indices = vectorize_layer(inputs)\n","# convertir los indices del vocabulario en predicciones\n","outputs = model(indices)\n","\n","# Fin del modelo\n","end_to_end_model = tf.keras.Model(inputs, outputs)\n","end_to_end_model.compile(\n","    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",")\n","\n","# probamos con el test sin procesar \n","end_to_end_model.evaluate(raw_test_ds)"],"execution_count":null,"outputs":[]}]}